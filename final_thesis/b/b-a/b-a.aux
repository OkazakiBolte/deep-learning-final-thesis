\relax 
\citation{bib : MNIST}
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章}方法}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}MNISTデータセット}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}フィードフォーワード・ニューラルネットワークによる学習}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}ベースとなるフィードフォーワード・ニューラルネットワークの構築}{1}\protected@file@percent }
\newlabel{subsec : ベースとなるフィードフォーワード・ニューラルネットワークの構築}{{1.2.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces MNISTデータセットの50個のデータ}}{2}\protected@file@percent }
\newlabel{fig : 50-MNIST-data}{{1.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces 最初に構築したシンプルなニューラルネットワーク}}{2}\protected@file@percent }
\newlabel{fig : simple-fnn}{{1.2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}活性化関数の比較}{3}\protected@file@percent }
\newlabel{subsec : 活性化関数の比較}{{1.2.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}コスト関数の比較}{3}\protected@file@percent }
\newlabel{subsec : コスト関数の比較}{{1.2.3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}最適化アルゴリズムの比較}{3}\protected@file@percent }
\newlabel{subsec : 最適化アルゴリズムの比較}{{1.2.4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}エポック数、バッチサイズの変更}{3}\protected@file@percent }
\newlabel{subsec : エポック数、バッチサイズの変更}{{1.2.5}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.6}隠れ層を２層に増やした場合の性能評価}{3}\protected@file@percent }
\newlabel{subsec : 隠れ層を２層に増やした場合の性能評価}{{1.2.6}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.7}隠れ層を３層以上に増やした場合の性能評価}{4}\protected@file@percent }
\newlabel{subsec : 隠れ層を３層以上に増やした場合の性能評価}{{1.2.7}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces 隠れユニット数が指数的に減少するニューラルネットワーク}}{4}\protected@file@percent }
\newlabel{fig : funnel}{{1.3}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces $a$と$N$の組み合わせ}}{4}\protected@file@percent }
\newlabel{tab : aとNの組み合わせ}{{1.1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.8}ドロップアウトの効果}{4}\protected@file@percent }
\newlabel{subsec : ドロップアウトによる効果}{{1.2.8}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}畳み込みニューラルネットワークによる学習}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}ベースとなる畳み込みニューラルネットワークの構築}{5}\protected@file@percent }
\newlabel{subsec : ベースとなる畳み込みニューラルネットワークの構築}{{1.3.1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces 畳み込み層が一つの畳み込みニューラルネットワーク}}{5}\protected@file@percent }
\newlabel{fig : simple-cnn}{{1.4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}フィルターのサイズと枚数の比較}{6}\protected@file@percent }
\newlabel{subsec : フィルターのサイズと枚数の比較}{{1.3.2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}プーリング層の追加}{6}\protected@file@percent }
\newlabel{subsec : プーリング層の追加}{{1.3.3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}LeNet-5の実装}{6}\protected@file@percent }
\newlabel{subsec : LeNet-5の実装}{{1.3.4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}畳み込みニューラルネットワークのアーキテクチャ}{6}\protected@file@percent }
\newlabel{subsec : 畳み込みニューラルネットワークのアーキテクチャ}{{1.3.5}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces 上図がネットワークA、下図がネットワークB}}{7}\protected@file@percent }
\newlabel{fig : nn-a-b}{{1.5}{7}}
