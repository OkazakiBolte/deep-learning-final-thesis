\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章}結果}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\newlabel{chap : 結果}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}フィードフォーワード・ニューラルネットワークによる学習}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}ベースとなるフィードフォーワード・ニューラルネットワークの構築}{1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces 隠れ層が１層のニューラルネットワークのコスト関数、正解率の時間発展}}{1}\protected@file@percent }
\newlabel{fig : 2}{{1.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces 先頭$100$個のテストデータに対するモデルの予測}}{2}\protected@file@percent }
\newlabel{fig : prediction-1}{{1.2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}活性化関数の比較}{2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces 活性化関数をシグモイド関数に変えた場合の学習曲線}}{3}\protected@file@percent }
\newlabel{fig : 8}{{1.3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}コスト関数の比較}{3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces コスト関数を平均二乗誤差に変えた場合の学習曲線}}{4}\protected@file@percent }
\newlabel{fig : 9}{{1.4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces コスト関数を平均二乗誤差とし、エポック数を増やした場合の学習曲線}}{4}\protected@file@percent }
\newlabel{fig : 11}{{1.5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}最適化アルゴリズムの比較}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces オプティマイザにAdamを採用した場合の学習曲線}}{5}\protected@file@percent }
\newlabel{fig : 10}{{1.6}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Adamを採用した場合の先頭$100$個のテストデータに対するモデルの予測}}{5}\protected@file@percent }
\newlabel{fig : predictions-2}{{1.7}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.5}エポック数、バッチサイズの変更}{6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces エポック数、バッチサイズを変更したときの実装結果}}{6}\protected@file@percent }
\newlabel{tab : エポック数、バッチサイズの変更}{{1.1}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.6}隠れ層を２層に増やした場合の性能評価}{6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces 第２隠れ層のユニット数を変化させたときの学習結果}}{7}\protected@file@percent }
\newlabel{tab : two-hidden-layers-1}{{1.2}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces 第１隠れ層と第２隠れ層のユニット数を入れ替えたときの学習結果の比較}}{7}\protected@file@percent }
\newlabel{tab : two-hidden-layers-2}{{1.3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.7}隠れ層を３層以上に増やした場合の性能評価}{7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces 隠れユニット数を$1/a$倍ずつ減らしていった多層ニューラルネットワークの学習結果}}{8}\protected@file@percent }
\newlabel{tab : 隠れ層を３層以上に増やした場合の性能評価}{{1.4}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {1.5}{\ignorespaces 「逆漏斗型」と「寸胴型」ネットワークによる学習結果}}{8}\protected@file@percent }
\newlabel{tab : 「逆漏斗型」と「寸胴型」ネットワークによる学習結果}{{1.5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.8}ドロップアウトによる効果}{8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces 学習が遅い場合の学習曲線}}{8}\protected@file@percent }
\newlabel{fig : 58}{{1.8}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces オプティマイザをAdamにして学習させたときの学習曲線}}{9}\protected@file@percent }
\newlabel{fig : 59}{{1.9}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {1.6}{\ignorespaces ドロップアウト率に対する性能の実験結果}}{9}\protected@file@percent }
\newlabel{tab : ドロップアウト率に対する性能の実験結果}{{1.6}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces $p = 0.75,\nobreakspace  {}$エポック数$100$のときの学習曲線}}{9}\protected@file@percent }
\newlabel{fig : 66}{{1.10}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces $p = 0.75,\nobreakspace  {}$エポック数$1000$のときの学習曲線}}{10}\protected@file@percent }
\newlabel{fig : 63}{{1.11}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}畳み込みニューラルネットワークによる学習}{10}\protected@file@percent }
\newlabel{sec : 畳み込みニューラルネットワークによる学習}{{1.2}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}ベースとなる畳み込みニューラルネットワークの構築}{10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces $3 \times 3$のフィルター$1$枚による畳み込みニューラルネットワークの学習曲線}}{11}\protected@file@percent }
\newlabel{fig : 40}{{1.12}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces 先頭$100$個のテストデータに対する畳み込みニューラルネットワークの予測}}{12}\protected@file@percent }
\newlabel{fig : prediction-3}{{1.13}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}フィルターのサイズと枚数の比較}{12}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.7}{\ignorespaces フィルター数を増加させたときの実行結果}}{12}\protected@file@percent }
\newlabel{tab : フィルター数を増加させたときの実行結果}{{1.7}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {1.8}{\ignorespaces フィルターサイズを変化させたときの実行結果}}{13}\protected@file@percent }
\newlabel{tab : フィルターサイズを変化させたときの実行結果}{{1.8}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}プーリング層の追加}{13}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.9}{\ignorespaces プーリングカーネルのサイズと対する実行結果}}{13}\protected@file@percent }
\newlabel{tab : プーリングカーネルのサイズと対する実行結果}{{1.9}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}LeNet-5の実装}{13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces LeNet-5の学習曲線}}{14}\protected@file@percent }
\newlabel{fig : 68}{{1.14}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {1.10}{\ignorespaces ドロップアウトを挿入したときの結果}}{14}\protected@file@percent }
\newlabel{tab : ドロップアウトを挿入したときの結果}{{1.10}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}畳み込みニューラルネットワークのアーキテクチャ}{15}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.11}{\ignorespaces ネットワークAとBについての実行結果}}{15}\protected@file@percent }
\newlabel{tab : ネットワークAとBについての実行結果}{{1.11}{15}}
