\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章}機械学習の基礎}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\jsc@mpt }}
\@writefile{lot}{\addvspace {10\jsc@mpt }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}教師あり学習}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}最適化}{2}\protected@file@percent }
\newlabel{eq : the-derivative-equals-to-zero}{{1.1}{3}}
\newlabel{enum : end-of-GD}{{2}{3}}
\newlabel{eq : GD}{{1.2}{3}}
\newlabel{enum : updating}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces 大域的最小と局所的最小}}{4}\protected@file@percent }
\newlabel{fig : mins}{{1.1}{4}}
\citation{bib : momentum-sdg}
\citation{bib : AdaGrad}
\newlabel{eq : momentum-sdg}{{1.3}{5}}
\newlabel{eq : adagrad}{{1.4}{5}}
\citation{bib : Adam}
\newlabel{eq : adam-m}{{1.5}{6}}
\newlabel{eq : adam-v}{{1.6}{6}}
\newlabel{eq : adam-m-hat}{{1.7}{6}}
\newlabel{eq : adam-v-hat}{{1.8}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}ベイズ推定}{6}\protected@file@percent }
\newlabel{eq : bayesian_inference}{{1.9}{6}}
\newlabel{eq : definition}{{1.10}{7}}
\newlabel{eq : iid}{{1.11}{7}}
\newlabel{eq : log}{{1.12}{7}}
\newlabel{eq : delta}{{1.13}{7}}
\newlabel{eq : expectation}{{1.14}{7}}
\newlabel{eq : flipping}{{1.15}{7}}
