%\documentclass{jsarticle}
%\documentclass[draft]
%\documentclass[dvipdfmx,autodetect-engine,draft]{jsarticle}% autodetect-engine ã§ pLaTeX / upLaTeX ã‚’è‡ªå‹•åˆ¤å®š
\documentclass[dvipdfmx,autodetect-engine]{jsarticle}% autodetect-engine ã§ pLaTeX / upLaTeX ã‚’è‡ªå‹•åˆ¤å®š

\usepackage[dvipdfmx]{graphicx}
\usepackage{url}
\usepackage{bm}
\usepackage{comment}
%\usepackage{split}
\usepackage{multirow}
\usepackage{listings,jlisting}
\usepackage{braket}
\usepackage{physics}
\usepackage{xparse,amsmath}
\usepackage{here}
\usepackage{enumerate}
\usepackage{mathrsfs}
%\usepackage{jlistings} %æ—¥æœ¬èªã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’ã™ã‚‹å ´åˆjlistingãŒå¿…è¦
\setcounter{tocdepth}{3}
\usepackage{amsmath,amssymb}

\usepackage{empheq}



%ã“ã“ã‹ã‚‰ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®è¡¨ç¤ºã«é–¢ã™ã‚‹è¨­å®š
\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}
\renewcommand{\lstlistingname}{ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰}
%ã“ã“ã¾ã§ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®è¡¨ç¤ºã«é–¢ã™ã‚‹è¨­å®š

%
% proof environment without \qed
%
\makeatletter
%\renewenvironment{proof}[1][\proofname]{\par
\newenvironment{Proof}[1][\Proofname]{\par
  \normalfont
  \topsep6\p@\@plus6\p@ \trivlist
  \item[\hskip\labelsep{\bfseries #1}\@addpunct{\bfseries.}]\ignorespaces
}{%
  \endtrivlist
}
%\renewcommand{\proofname}{è¨¼æ˜}
%\renewcommand{\proofname}{Proof}
\newcommand{\Proofname}{è¨¼æ˜}
%\newcommand{\Proofname}{Proof}
\makeatother
%
% \qed
%
\makeatletter
\def\BOXSYMBOL{\RIfM@\bgroup\else$\bgroup\aftergroup$\fi
  \vcenter{\hrule\hbox{\vrule height.85em\kern.6em\vrule}\hrule}\egroup}
\makeatother
\newcommand{\BOX}{%
  \ifmmode\else\leavevmode\unskip\penalty9999\hbox{}\nobreak\hfill\fi
  \quad\hbox{\BOXSYMBOL}}
%\renewcommand\qed{\BOX}
\newcommand\QED{\BOX}



\begin{document}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%ã‹ã‘ã‚‹10ã®ãªã‚“ã¨ã‹ä¹—
\newcommand{\E}[1]{ \times 10^{#1}}
%æ•°å¼ä¸­ã®å˜ä½ï¼ˆç©ºç™½ä»˜ãï¼‰
\newcommand{\un}[1]{~{\rm #1}}
%æ•°å¼å†…ã®æ—¥æœ¬èª
\newcommand{\jp}[1]{\mbox{#1}}




\def\T{\mathsf{T}}
\def\y{\vb*{y}}
\def\w{\vb*{w}}
\newcommand{\argmax}{\mathop{\rm argmax}\limits}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



\begin{flushright}
ä½œæˆæ—¥ï¼š\today
\\æ…¶æ‡‰ç¾©å¡¾å¤§å­¦ç†å·¥å­¦éƒ¨ç‰©ç†å­¦ç§‘\\å²¡å´å¥äºº
\end{flushright}
\begin{center}
{\Large å’ç ”ã‚¼ãƒŸã€Œæ·±å±¤å­¦ç¿’ã€} 
\end{center}
%ç®‡æ¡æ›¸ã
%\tableofcontents   %ğŸ‘ˆç›®æ¬¡
%\newpage


%%%%%%%%%%%%%%%%%%%%%%%
%2.6ç¯€
\setcounter{section}{4}
\section{æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤}
\setcounter{subsection}{5}
\subsection{ãƒ™ã‚¤ã‚ºçµ±è¨ˆ}
ãƒ‡ãƒ¼ã‚¿$D_m := \qty{x^{(1)},\ldots,x^{(m)}}$ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦æ±ºã¾ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒ$\vb*{\theta}$ã¨ã„ã†å€¤ã‚’ã¨ã‚Šã†ã‚‹ç¢ºç‡ã¯ãƒ™ã‚¤ã‚ºã®å®šç†ã‚ˆã‚Š
\begin{eqnarray}
p\qty(\vb*{\theta} \mid D_m) = \frac{ p\qty(D_m\mid \vb*{\theta}) p\qty(\vb*{\theta})}{p\qty(D_m)} \propto p\qty(D_m \mid \vb*{\theta}) p\qty(\vb*{\theta}) \label{Bayes}
\end{eqnarray}
ã¨ãªã‚‹ã€‚ä¸­è¾ºã®åˆ†æ¯ã¯
$$p\qty(D_m) = \int p\qty(D_m \mid \vb*{\theta}) p\qty(\vb*{\theta}) \dd{\vb*{\theta}}$$
ã§è¨ˆç®—ã§ãã€ã“ã‚Œã¯$\vb*{\theta}$ã«ã‚ˆã‚‰ãšã€ã¾ãŸ$D_m=\qty{x^{(1)},\ldots,x^{(m)}}$ã®å€¤ã¯æ—¢çŸ¥ã®ã‚‚ã®ã§ã‚ã‚‹ã‹ã‚‰ã€å®šæ•°ã¨ã—ã¦æ‰±ã£ã¦ã‚ˆã„ã€‚å¼(\ref{Bayes})ã®$p\qty(\vb*{\theta})$ã‚’äº‹å‰ç¢ºç‡ï¼ˆåˆ†å¸ƒï¼‰ã€$p\qty(\vb*{\theta} \mid D_m )$ã‚’äº‹å¾Œç¢ºç‡ï¼ˆåˆ†å¸ƒï¼‰ã€$p\qty( D_m \mid \vb*{\theta})$ã‚’å°¤åº¦ã¨ã„ã†ã€‚äº‹å‰ç¢ºç‡ã¯ãƒ‡ãƒ¼ã‚¿ã‚’æ‰‹ã«å…¥ã‚Œã‚‹å‰ã«æƒ³å®šã—ã¦ã„ãŸç¢ºç‡ã§ã‚ã‚‹ã®ã«å¯¾ã—ã¦ã€äº‹å¾Œç¢ºç‡ã¯ãƒ‡ãƒ¼ã‚¿ã‚’å¾—ãŸã‚ã¨ã«äº‹å‰ç¢ºç‡ã‚’ä¿®æ­£ï¼ˆãƒ™ã‚¤ã‚ºä¿®æ­£ï¼‰ã—ãŸã‚‚ã®ã§ã‚ã‚‹ã€‚å¼(\ref{Bayes})ã‹ã‚‰ã‚ã‹ã‚‹ã‚ˆã†ã«ã€ãƒ™ã‚¤ã‚ºä¿®æ­£ã¨ã¯äº‹å‰ç¢ºç‡ã«å°¤åº¦ã‚’ã‹ã‘ã¦è¦æ ¼åŒ–ã—ã€ã‚ˆã‚Šã‚‚ã£ã¨ã‚‚ã‚‰ã—ã„åˆ†å¸ƒã«ä¿®æ­£ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚

\subsubsection*{ä¾‹ï¼šãƒ™ã‚¤ã‚ºç·šå½¢å›å¸°}
$m$å€‹ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿$\qty(X^{(\mathrm{train})},\vb*{y}^{(\mathrm{train})})=\qty(X,\vb*{y})$ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ã™ã‚‹ï¼ˆå³è‚©ã®(train)ã¯çœç•¥ã™ã‚‹ï¼‰ã€‚ã“ã“ã«$\vb*{y}=\qty[y_1,\ldots,y_m]^\T$ã§ã‚ã‚Šã€åŸºåº•é–¢æ•°ã‚’$\phi_k(x),~k=0,\ldots,n$ã¨ã™ã‚Œã°è¨ˆç”»è¡Œåˆ—ã¯$\qty(X)_{ij}=\phi_j\qty(x_ i)$ã§ã‚ã‚‹ï¼ˆæ¨å®šã™ã‚‹é–¢æ•°ã‚’$n$æ¬¡å¤šé …å¼ã¨ä»®å®šã—ãŸã¨ãã¯$\phi_k(x)=x^k$ã§ã‚ã£ãŸï¼‰ã€‚
$\vb*{x}=\qty[ \phi_0 (x),\ldots,\phi_n(x) ]^\T,~\vb*{w} = \qty[w_0, w_1, \ldots, w_n]^\T$ã¨ã™ã‚Œã°ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹$y$ã®æ¨å®šã¯$\hat{y}=\displaystyle\sum_{k=0}^{n} w_k \phi_k(x) =\vb*{w}^\T \vb*{x}$ã¨è¡¨ç¾ã§ãã‚‹ã€‚ã¾ãŸå„è¨“ç·´ãƒ‡ãƒ¼ã‚¿$x_i~ (i=1,\ldots,m)$ã«å¯¾ã™ã‚‹$y$ã®æ¨å®šã‚’è¨ˆç®—ã—ãŸ$\hat{y}_i =\displaystyle\sum_{k=0}^{n} w_k \phi_k(x_i)$ã‚’ä¸¦ã¹ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’$\hat{\vb*{y}}=\mqty[\hat{y}_1 , \ldots,\hat{y}_m]^\T$ã¨æ›¸ã‘ã°ã€$\hat{\vb*{y}} = X \vb*{w}$ã§ã‚ã‚‹ã€‚\\

ã•ã¦$X,~\vb*{y}$ãŒå¾—ã‚‰ã‚ŒãŸã‚‚ã¨ã§ä¿‚æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒ$\vb*{w}$ã¨ãªã‚‹æ¡ä»¶ä»˜ãç¢ºç‡$p\qty(\vb*{w} \mid X,\vb*{y})$ã‚’æ±‚ã‚ãŸã„ã€‚
\begin{equation}
p\qty(\vb*{w} \mid X,\vb*{y}) = \frac{p\qty(\vb*{y} \mid X,\vb*{w}) p(X \mid \vb*{w}) p(\vb*{w})}{ p(X,\vb*{y})} \propto p\qty(\vb*{y} \mid X,\vb*{w}) p(\vb*{w}). \label{pp}
\end{equation}
å°¤åº¦ã‚’$p(\vb*{y} \mid X,\vb*{w})$ã¨ã—ãŸã®ã¯ç†ç”±ãŒã‚ã‚‹ã€‚ãƒ™ã‚¤ã‚ºã®å®šç†ã‚’è€ƒãˆã‚Œã°ã€å°¤åº¦ã¨ã—ã¦ã®å€™è£œã¯$p(X,\vb*{y} \mid \vb*{w}),~p(X \mid \vb*{y},\vb*{w}),~ p(\vb*{y} \mid X,\vb*{w})$ã®ï¼“ã¤ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚ã—ã‹ã—æ¨å®šã—ãŸã„é–¢æ•°$\hat{y}$ã¯$X$ã¨$\vb*{w}$ãŒæ±ºã¾ã‚Œã°æ±ºã¾ã‚‹ã¨ã„ã†ã‚‚ã®ãªã®ã§ã€å°¤åº¦ã¨ã—ã¦ã¯$p(\vb*{y} \mid X,\vb*{w})$ãŒé©å½“ã§ã‚ã‚‹ã€‚ã¾ãŸ$\vb*{w}$ã®å€¤ã¯$X,~\vb*{y}$ã®å€¤ã«ã‚ˆã£ã¦æ±ºã‚ã‚‰ã‚Œã‚‹ä¸ç¢ºã‹ã•ã‚’æŒã£ã¦ã„ã‚‹ãŒã€$X$ã®å€¤ã¯è¦³æ¸¬ã•ã‚ŒãŸæ—¢çŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã§å›ºå®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€$\vb*{w}$ã®å€¤ãŒã‚ã‹ã£ã¦ã„ã‚‹æ¡ä»¶ã®ã‚‚ã¨ã§ãƒ‡ãƒ¼ã‚¿ã®å€¤ãŒ$X$ã§ã‚ã‚‹æ¡ä»¶ä»˜ãç¢ºç‡$p(X\mid \vb*{w})$ã¯ã€$\vb*{w}$ã®å€¤ã«ã‚ˆã‚‰ãšå¸¸ã«$1$ã§ã‚ã‚‹ã€‚ã¾ãŸå¼(\ref{pp})ã®åˆ†æ¯ã¯$\vb*{w}$ã«ã¤ã„ã¦ç©åˆ†ã‚’ã—ãŸã‚‚ã®ãªã®ã§ã€$\vb*{w}$ã«ã‚ˆã‚‰ãªã„å®šæ•°ã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚\\

å°¤åº¦$p\qty(\vb*{y} \mid X,\vb*{w})$ãŒæ­£è¦åˆ†å¸ƒã«å¾“ã†ã¨ãã€å¼(\ref{pp})ã®äº‹å¾Œç¢ºç‡ã‚’å…·ä½“çš„ã«è¨ˆç®—ã™ã‚‹ä¾‹ã‚’ã¿ã›ã‚‹ã€‚
\begin{eqnarray}
p\qty(\vb*{y} \mid X,\vb*{w}) = \mathcal{N}\qty(\vb*{y};X\vb*{w},I)\propto \exp\qty(-\frac{1}{2} \qty(\vb*{y} - X \vb*{w} )^\T \qty(\vb*{y} - X \vb*{w} ) ). \label{likelihood}
\end{eqnarray}
ãªãŠå¤šå¤‰é‡æ­£è¦åˆ†å¸ƒã¯
\begin{equation}
\mathcal{N} \qty(\vb*{x}; \vb*{\mu}, \Sigma)= \sqrt{\frac{1}{\qty(2 \pi)^n \det \Sigma}} \exp \qty(-\frac{1}{2} \qty(\vb*{x}-\vb*{\mu})^\T \Sigma^{-1} \qty(\vb*{x}-\vb*{\mu})) \label{3.23}
\end{equation}
ã§ã‚ã£ãŸï¼ˆæ•™ç§‘æ›¸ã®å¼3.23ï¼‰ã€‚ã“ã®$\vb*{\mu}$ã¯$\vb*{x}$ã®å„æˆåˆ†ã®å¹³å‡ã‚’ä¸¦ã¹ãŸãƒ™ã‚¯ãƒˆãƒ«ã§ã€$\Sigma$ã¯åˆ†æ•£å…±åˆ†æ•£è¡Œåˆ—ã§ã‚ã‚‹ã€‚ãŸã ã—å¼(\ref{likelihood})ã§ã¯å„$y_i$ã®åˆ†æ•£$s_i^2$ã¯$1$ã§ã€$i\neq j$ã«å¯¾ã—ã¦$y_i$ã¨$y_j$ã®å…±åˆ†æ•£$s_{ij}$ã¯ã‚¼ãƒ­ã€ã™ãªã‚ã¡ç›¸é–¢ã¯ãªã„ã¨ä»®å®šã—ã¦ã„ã‚‹ã€‚å¼(\ref{likelihood})ã¯ã€è¦³æ¸¬å€¤$\vb*{y}=\qty[y_1,\ldots,y_m]^\T$ã®ãšã‚Œå…·åˆãŒæ­£è¦åˆ†å¸ƒã«å¾“ã†ã¨ä»®å®šã—ã¦ã„ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¦ã„ã‚‹\cite{1}ã€‚

äº‹å‰ç¢ºç‡ã¯ãƒ‡ãƒ¼ã‚¿ã‚’å¾—ã‚‹å‰ã«æƒ³å®šã—ã¦ã„ãŸç¢ºç‡ã®ã“ã¨ã§ã‚ã‚‹ã‹ã‚‰ã€éå»ã®çµŒé¨“ã«ã‚‚ã¨ã¥ã„ãŸã€æƒ³å®šã—ã¦ã„ãŸåˆ†å¸ƒã‚’è¨­å®šã™ã‚Œã°ã‚ˆã„ã€‚ã¤ã¾ã‚Šäºˆæƒ³ã¨ã‹ã€Œç›´æ„Ÿçš„ä¿¡é ¼åº¦ï¼ˆthe degree of beliefï¼‰ã€ã§ã‚ˆã„ã€‚ãŸã¨ãˆã°ä½•ã‚‚æƒ…å ±ã‚’å¾—ã¦ãŠã‚‰ãšã€ã©ã‚“ãªåˆ†å¸ƒã‹ã‚‚ã‚ã‹ã‚‰ãªã„å ´åˆã¯ã€ãŸã å˜ã«å®šæ•°ã¨ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ï¼ˆç„¡æƒ…å ±äº‹å‰åˆ†å¸ƒã€non-informative priorã¨ã„ã†\cite{2}ï¼‰ã€‚ã“ã“ã§ã¯è¨ˆç®—ã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ã€äº‹å‰åˆ†å¸ƒã¯å°¤åº¦ã¨åŒã˜ãæ­£è¦åˆ†å¸ƒã¨è¨­å®šã™ã‚‹ã€‚
\begin{equation}
p( \vb*{w} ) = \mathcal{N}\qty(\vb*{w} ; \vb*{\mu}_0 , \Lambda_0) \propto \exp \qty(- \frac{1}{2} \qty(\vb*{w} - \vb*{\mu}_0)^\T \Lambda_0^{-1} \qty(\vb*{w} - \vb*{\mu}_0) ). \label{posterior}
\end{equation}
å®Ÿç”¨ä¸Šã€$\Lambda_0 =\mathrm{diag}\qty(\vb*{\lambda}_0)$ãªã©ã¨ã™ã‚Œã°è¨ˆç®—ã¯ã•ã‚‰ã«ç°¡å˜ã«ãªã‚‹ã€‚




äº‹å¾Œç¢ºç‡ã¯å°¤åº¦ã¨äº‹å‰ç¢ºç‡ã®ç©ã«æ¯”ä¾‹ã™ã‚‹ã®ã§ã€å¼(\ref{pp})ã€å¼(\ref{likelihood})ã€å¼(\ref{posterior})ã‚ˆã‚Š
\begin{equation*}
p\qty(\vb*{w} \mid X,\vb*{y}) \propto \exp\qty(-\frac{1}{2} \qty(\vb*{y} - X \vb*{w} )^\T \qty(\vb*{y} - X \vb*{w} ) ) \exp \qty(- \frac{1}{2} \qty(\vb*{w} - \vb*{\mu}_0)^\T \Lambda_0^{-1} \qty(\vb*{w} - \vb*{\mu}_0) ).
\end{equation*}
ã“ã‚Œã¯$e^x e^y = e^{x+y}$ã®ã‚ˆã†ã«ã²ã¨ã¤ã®æŒ‡æ•°é–¢æ•°ã«ã¾ã¨ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚æŒ‡æ•°é–¢æ•°ã®è‚©ã®éƒ¨åˆ†ã‚’å±•é–‹ã—ã¦ã€$\w$ã®äºŒæ¬¡å½¢å¼$-\frac{1}{2} \qty(\w-\vb*{\mu}_m)^\T \Lambda_{m}^{-1} \qty(\w-\vb*{\mu}_m)$ã®å½¢ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚ã¾ãš$\Lambda_0^{-1}$ã¯å¯¾ç§°è¡Œåˆ—ã§ã‚ã‚Šã€$\w^\T X^\T \y $ã¨$w^\T \Lambda_{0}^{-1} \vb*{\mu_0} $ã¯ã‚¹ã‚«ãƒ©ãƒ¼ã§ã‚ã‚‹ã‹ã‚‰ã€$\w^\T X^\T \y =\qty(\w^\T X^\T \y)^\T=\y^\T X \w,~~\w^\T \Lambda_{0}^{-1} \vb*{\mu_0} =\qty(\w^\T \Lambda_{0}^{-1} \vb*{\mu_0} )^\T = \vb*{\mu}_0^\T  \Lambda_{0}^{-1} \w$ã®ã‚ˆã†ã«ã€é …ã®å·¦å´ã«ã‚ã‚‹$\w^\T$ã‚’é …ã®å³å´ã«ç§»ã™ã“ã¨ãŒã§ãã‚‹ã€‚
\begin{eqnarray*}
-\frac{1}{2} \qty(\vb*{y} - X \vb*{w} )^\T \qty(\vb*{y} - X \vb*{w} ) &=&  -\frac{1}{2} \qty(  \y^\T \y -\y^\T X \w -\w^\T X^\T \y +\w^\T X^\T X \w    ) \\
&=& -\frac{1}{2} \qty( \mathrm{const.}-2\y^\T X \w +\w^\T X^\T X \w    ) ,
\end{eqnarray*}
\begin{eqnarray*}
-\frac{1}{2} \qty( \w - \vb*{\mu}_0 )^\T \Lambda_{0}^{-1}  \qty( \w - \vb*{\mu}_0 ) 
&=& -\frac{1}{2} \qty(\w^\T  \Lambda_{0}^{-1} \w  -\w^\T  \Lambda_{0}^{-1} \vb*{\mu}_0 - \vb*{\mu}_0^\T  \Lambda_{0}^{-1} \w + \vb*{\mu}_0^\T  \Lambda_{0}^{-1} \vb*{\mu}_0) \\
&=& -\frac{1}{2} \qty(\w^\T  \Lambda_{0}^{-1} \w   - 2\vb*{\mu}_0^\T  \Lambda_{0}^{-1} \w + \mathrm{const.}).
\end{eqnarray*}
ãŸã ã—$\w$ã«ã‚ˆã‚‰ãªã„é …ã¯å®šæ•°$\mathrm{const.}$ã¨ã—ãŸã€‚ã‚†ãˆã«äº‹å¾Œç¢ºç‡ã¯
\begin{eqnarray}
p\qty(\w \mid X,\y) &\propto& \exp\qty(-\frac{1}{2}\qty(-2\y^\T X \w +\w^\T X^\T X \w + \w^\T  \Lambda_{0}^{-1} \w   - 2\vb*{\mu}_0^\T  \Lambda_{0}^{-1} \w) ) \nonumber  \\
&=& \exp\qty(-\frac{1}{2} \qty[-2\qty(\y^\T X + \vb*{\mu}_0^\T \Lambda_0^{-1} )\w + \w^\T \qty(X^\T X + \Lambda_{0}^{-1}) \w] ). \label{æ¯”è¼ƒå¯¾ç§°}
\end{eqnarray}
ã“ã“ã§ã€ç›®æŒ‡ã—ã¦ã„ã‚‹äºŒæ¬¡å½¢å¼ã‚’å±•é–‹ã™ã‚‹ã¨
$$-\frac{1}{2} \qty(\w-\vb*{\mu}_m)^\T \Lambda_{m}^{-1} \qty(\w-\vb*{\mu}_m) = -\frac{1}{2} \qty( -2 \vb*{\mu}_{m}^\T \Lambda_{m}^{-1} \w +\w^\T \Lambda_{m}^{-1} \w )+ \mathrm{const.}$$
ã§ã‚ã‚‹ã‹ã‚‰ã€ã“ã‚Œã¨å¼(\ref{æ¯”è¼ƒå¯¾ç§°})ã®å¼•æ•°éƒ¨åˆ†ã‚’æ¯”è¼ƒã—ã¦ã€$\Lambda_{m}^{-1} = X^\T X +\Lambda_{0}^{-1},~~\vb*{\mu}_{m}^{\T} \Lambda_{m}^{-1} = \y^\T X + \vb*{\mu}_{0}^{\T}\Lambda_{0}^{-1}$ã‚’å¾—ã‚‹ã€‚ã™ãªã‚ã¡
$$\Lambda_{m} = \qty(X^\T X +\Lambda_{0}^{-1})^{-1},~~~~\vb*{\mu}_{m} = \Lambda_{m} \qty(X^\T \y +\Lambda_{0}^{-1} \vb*{\mu}_0)$$
ã¨ã—ã¦ã€äº‹å‰åˆ†å¸ƒãŒæ­£è¦åˆ†å¸ƒã«å¾“ã†ã¨ãäº‹å¾Œç¢ºç‡ã¯
$$p\qty( \w \mid X,\y  ) \propto \exp\qty(-\frac{1}{2} \qty(\w-\vb*{\mu}_m)^\T \Lambda_{m}^{-1} \qty(\w-\vb*{\mu}_m))$$
ã¨ãªã‚Šã€ã“ã‚Œã‚‚ã¾ãŸæ­£è¦åˆ†å¸ƒã«å¾“ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚è¦æ ¼åŒ–ã‚’ã™ã‚‹ã«ã¯å¼(\ref{3.23})ã‚’å‚ç…§ã™ã‚Œã°ã‚ˆã„ã€‚ã“ã®è¨ˆç®—çµæœã¯ã€ã¯ã˜ã‚$\w$ã¯å¹³å‡$\vb*{\mu}_0,~$åˆ†æ•£å…±åˆ†æ•£è¡Œåˆ—$\Lambda_0$ã®æ­£è¦åˆ†å¸ƒã«å¾“ã†ã¨æƒ³å®šã—ã¦ã„ãŸã‚‚ã®ãŒã€ãƒ‡ãƒ¼ã‚¿$X,~\y$ã‚’å¾—ãŸã“ã¨ã«ã‚ˆã‚Šã€å¹³å‡$\vb*{\mu}_m,~$åˆ†æ•£å…±åˆ†æ•£è¡Œåˆ—$\Lambda_m$ã®æ­£è¦åˆ†å¸ƒã«å¾“ã†ã‚ˆã†ã«ä¿®æ­£ã•ã‚ŒãŸã“ã¨ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚ãŸã ã—$\Lambda_m$ãŒæ­£å‰‡ã«ãªã‚‹ã‚ˆã†ã«$\Lambda_0$ã‚’è¨­å®šã™ã‚‹å¿…è¦ã¯ã‚ã‚‹ã€‚ã“ã®ä¾‹ã®ã‚ˆã†ã«ã€äº‹å‰åˆ†å¸ƒã¨äº‹å¾Œåˆ†å¸ƒãŒåŒã˜åˆ†å¸ƒæ—ã«ãªã‚‹ã¨ãã€ã“ã‚Œã‚’å…±å½¹è‡ªç„¶åˆ†å¸ƒã¨ã„ã†\cite{2}ã€‚

äº‹å‰ç¢ºç‡ã«ãŠã„ã¦$\vb*{\mu}_0 = \vb*{0},~\Lambda_0 = \frac{1}{\lambda} I$ã¨è¨­å®šã—ãŸå ´åˆã€äº‹å¾Œç¢ºç‡ã«ãŠã„ã¦$\Lambda_{m}^{-1} = X^\T X +\lambda I,~\vb*{\mu}_m = \Lambda_m X^\T \y $ã¨ãªã‚‹ã®ã§ã€$\w$ã®çœŸã®å€¤$\vb*{\mu}_m$ã«ã¤ã„ã¦ã®æ–¹ç¨‹å¼
$$\Lambda_{m}^{-1} \vb*{\mu}_m = \qty(X^\T X +\lambda I) \vb*{\mu}_m = X^\T \y. $$
ãŒå¾—ã‚‰ã‚Œã‚‹ã€‚ã“ã“ã§$X$ã¨$\vb*{y}$ã¯æœ‰é™å€‹ã®è¦³æ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹ãŸã‚ã€ã“ã®æ–¹ç¨‹å¼ã‚’è§£ã„ã¦å¾—ã‚‰ã‚Œã‚‹$\vb*{\mu}_m$ã®å€¤ã¯å®Ÿéš›ã«ã¯$\w$ã®æ¨å®šå€¤$\hat{\vb*{\mu}}_m$ã§ã‚ã‚‹ã€‚ã“ã®æ–¹ç¨‹å¼ã¯ã€æ­£å‰‡åŒ–é …ã‚’é‡ã¿æ¸›è¡°$\lambda \norm{\w}_2^2$ã¨ã—ã¦æ­£å‰‡åŒ–æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚Šå¾—ã‚‰ã‚ŒãŸæ–¹ç¨‹å¼$ \qty(X^\T X +\lambda I) \w = X^\T \y$ã«ä¸€è‡´ã—ã¦ã„ã‚‹ã€‚ãŸã ã—$\lambda=0$ã¨ã—ã¦ã—ã¾ã†ã¨ã€ã“ã‚Œã¯$\w$ã®åˆ†æ•£ãŒã¯ã˜ã‚ç„¡é™å¤§ã§ã‚ã£ãŸã“ã¨ã‚’è¡¨ã—ã¦ã„ã‚‹ãŒã€$\Lambda_0,~\Lambda_0^{-1}$ã‚’å®šç¾©ã§ããªã„ãŸã‚ã€ãƒ™ã‚¤ã‚ºæ¨å®šã§ã¯ã“ã®å ´åˆã‚’å–ã‚Šæ‰±ã†ã“ã¨ãŒã§ããªã„ã€‚ã•ã‚‰ã«é‡è¦ãªé•ã„ã¨ã—ã¦ã¯ã€æ­£å‰‡åŒ–æœ€å°äºŒä¹—æ³•ã§ã¯$\w$ã®æ¨å®šå€¤ã®ã¿å¾—ã‚‰ã‚Œã¦ã„ãŸãŒã€ãƒ™ã‚¤ã‚ºæ¨å®šã§ã¯ãã‚Œã«åŠ ãˆã¦$\w$ã®åˆ†æ•£å…±åˆ†æ•£è¡Œåˆ—$\Lambda_m$ã‚‚å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

\subsubsection{MAPæ¨å®š}
äº‹å¾Œç¢ºç‡$p\qty(\vb*{\theta} \mid D_m)$ãŒæœ€å¤§ã«ãªã‚‹ã¨ãã®$\vb*{\theta}$ã®å€¤ã‚’ãã®æ¨å®šå€¤ã¨ã™ã‚‹æ–¹æ³•ã‚’ã€MAPæ¨å®šï¼ˆæœ€å¤§äº‹å¾Œç¢ºç‡æ¨å®šã€maximum a posteriori  estimationï¼‰ã¨ã„ã†ã€‚ã™ãªã‚ã¡ãã®æ¨å®šå€¤ã‚’$\hat{\vb*{\theta}}_{\mathrm{MAP}}$ã¨ã‹ã‘ã°ã€
$$\hat{\vb*{\theta}}_{\mathrm{MAP}} = \argmax_{\vb*{\theta}} p\qty(\vb*{\theta} \mid D_m) =  \argmax_{\vb*{\theta}}  \qty[\log p\qty(\vb*{\theta} \mid D_m)] =\argmax_{\vb*{\theta}}  \qty[\log p\qty(D_m \mid \vb*{\theta}) + \log p\qty(\vb*{\theta})]$$
ã§ã‚ã‚‹ã€‚ãŸã ã—ã“ã“ã§ã¯é–¢æ•°$f\qty(\vb*{\theta})$ã®æœ€å¤§ç‚¹ã¨$\log f\qty(\vb*{\theta})$ã®æœ€å¤§ç‚¹ãŒä¸€è‡´ã™ã‚‹ã“ã¨ã¨ã€$p\qty(\vb*{\theta} \mid D_m) \propto p\qty(D_m \mid \vb*{\theta}) p\qty(\vb*{\theta})$ã§ã‚ã‚‹ã“ã¨ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚\\

ä¾‹ã¨ã—ã¦ã€ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦äº‹å‰åˆ†å¸ƒ$p\qty(\w)$ãŒæ­£è¦åˆ†å¸ƒ$\mathcal{N} \qty(\w; \vb*{0},\frac{1}{\lambda} I)$ã«å¾“ã†ã¨è¨­å®šã™ã‚‹ã€‚ã™ã‚‹ã¨
$$p\qty(\w) \propto \exp\qty(-\frac{1}{2} \lambda\w^\T \w), ~~~\log p\qty(\w) =-\frac{\lambda}{2} \w^\T \w + \mathrm{const.}$$
ã§ã‚ã‚‹ã‹ã‚‰ã€
$$\log p\qty(\w \mid X,\y) = \log p\qty(\y \mid X,\w) + \log p\qty(\w) + \mathrm{const.} =-\mathrm{MSE}(\w) -\frac{\lambda}{2}\w^\T \w + \mathrm{const.}$$
ã§ã‚ã‚‹ã€‚ã“ã‚Œã¯æœ€å°¤æ¨å®šæ³•ã§æœ€å¤§åŒ–ã™ã‚‹é–¢æ•°ï¼ˆå¼5.65ï¼‰ã«é‡ã¿æ¸›è¡°ã‚’ä»˜åŠ ã—ãŸã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ç¬¦å·ãŒãƒã‚¤ãƒŠã‚¹ã¨ãªã£ã¦ã„ã‚‹ã‹ã‚‰ã€ã“ã‚Œã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã¯ã€æ­£å‰‡åŒ–æœ€å°äºŒä¹—æ³•ã«ãŠã‘ã‚‹$\mathrm{MSE}(\w) +\frac{\lambda}{2}\w^\T \w$ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã¨ç­‰ä¾¡ã§ã‚ã‚‹ã€‚ãªãŠå¼ã«å®šæ•°ãŒè¶³ã•ã‚Œã¦ã„ã‚‹ãŒã€æœ€å¤§ãƒ»æœ€å°ã¨ãªã‚‹ç‚¹ã¯ãã‚Œã«ã‚ˆã£ã¦å½±éŸ¿ã•ã‚Œãªã„ã®ã§ã€ã‚„ã£ã¦ã„ã‚‹ã“ã¨ã¯æ­£å‰‡åŒ–æœ€å°äºŒä¹—æ³•ã¨åŒã˜ã§ã‚ã‚‹ã€‚

As with full Bayesian inference, MAP Bayesian inference has the advantage of leveraging information that is brought by the prior and cannot be found in the training data. This additional information helps to reduce the variance in the MAP point estimate (in comparison to the ML estimate). However, it does so at the price of increased bias.
ãªãœï¼Ÿ

ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ã¿ã§ã¯å¾—ã‚‰ã‚Œãªã„ã‚ˆã†ãªæƒ…å ±ã‚’äº‹å‰ç¢ºç‡ã‹ã‚‰å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã€MAPæ¨å®šã¯æœ‰ç”¨ã§ã‚ã‚‹ã€‚ãã‚Œã«ã‚ˆã£ã¦æ¨å®šé‡ã®ãƒãƒªã‚¢ãƒ³ã‚¹ã‚’æœ€å°¤æ¨å®šã«æ¯”ã¹ã¦å°ã•ãã™ã‚‹ã“ã¨ãŒã§ãã‚‹ãŒã€ãã®ã¨ããƒã‚¤ã‚¢ã‚¹ã®å¢—å¤§ãŒä¼´ã†ã€‚

æ­£å‰‡åŒ–ã‚’å«ã‚€æ¨å®šæ–¹æ³•ã®å¤šãã¯ã€è£ã§MAPæ¨å®šã‚’è¡Œãªã£ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã€ãã®æ­£å‰‡åŒ–é …ã¯$\log p\qty(\vb*{\theta})$ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚ãŸã ã—ã™ã¹ã¦ã®æ­£å‰‡åŒ–é …ãŒ$\log p\qty(\vb*{\theta})$ã«å¯¾å¿œã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚ä¾‹ãˆã°æ­£å‰‡åŒ–é …ãŒãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã¨ãã€$p\qty(\vb*{\theta})$ã¯$\vb*{\theta}$ã®ã¿ã«ã‚ˆã‚‹ç¢ºç‡å¯†åº¦é–¢æ•°ã§ã‚ã‚‹ãŸã‚ã€ã€Œæ­£å‰‡åŒ–é …ã¯$\log p\qty(\vb*{\theta})$ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€ã¨è€ƒãˆã‚‹ã“ã¨ã¯ã§ããªã„ã€‚

é€†ã«MAPæ¨å®šã«ã‚ˆã£ã¦æ­£å‰‡åŒ–é …ã‚’è¨­è¨ˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
















\begin{comment}
\newpage
\section*{ãƒ™ã‚¤ã‚ºæ¨å®š}
äº‹å‰ç¢ºç‡ï¼ˆprior probabilityï¼‰ã¨ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’æ‰‹ã«å…¥ã‚Œã‚‹å‰ã«æƒ³å®šã—ã¦ã„ãŸç¢ºç‡ã®ã“ã¨ã€‚äº‹å¾Œç¢ºç‡ï¼ˆposterior probabilityï¼‰ã¨ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦äº‹å‰ç¢ºç‡ã‚’ä¿®æ­£ï¼ˆãƒ™ã‚¤ã‚ºä¿®æ­£ï¼‰ã—ãŸçµæœã®ç¢ºç‡ã®ã“ã¨ã€‚

ã‚¯ãƒƒã‚­ãƒ¼ã®ãŸãã•ã‚“è©°ã¾ã£ãŸãƒœã‚¦ãƒ«ãŒï¼’ã¤ã‚ã‚‹ã€‚ãƒœã‚¦ãƒ«ï¼‘ã«ã¯ãƒãƒ§ã‚³ãƒãƒƒãƒ—ã‚¯ãƒƒã‚­ãƒ¼ãŒ10æšã€ãƒ—ãƒ¬ãƒ¼ãƒ³ã‚¯ãƒƒã‚­ãƒ¼ãŒ30æšå…¥ã£ã¦ã„ã¦ã€ãƒœã‚¦ãƒ«ï¼’ã«ã¯ãã‚Œãã‚Œ20æšãšã¤å…¥ã£ã¦ã„ã‚‹ã€‚ãƒœã‚¦ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã¨ã‚Šã€ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–ã‚Šå‡ºã—ãŸã¨ã“ã‚ã€ãƒ—ãƒ¬ãƒ¼ãƒ³ã§ã‚ã£ãŸã€‚ã“ã®ã¨ãã€ã©ã¡ã‚‰ã®ãƒœã‚¦ãƒ«ãŒé¸ã°ã‚ŒãŸã®ã ã‚ã†ã‹ï¼Ÿã€€ãƒœã‚¦ãƒ«ï¼‘ã®ã»ã†ãŒãƒ—ãƒ¬ãƒ¼ãƒ³ã‚¯ãƒƒã‚­ãƒ¼ã®å‰²åˆãŒå¤§ãã„ã®ã§ã€ç›´æ„Ÿçš„ã«ã¯ãƒœã‚¦ãƒ«ï¼‘ãŒç­”ãˆãªæ°—ãŒã™ã‚‹ã€‚æ­£ç¢ºãªç­”ãˆã‚’ãƒ™ã‚¤ã‚ºæ¨å®šã‚’ç”¨ã„ã¦å‡ºãã†ã€‚ãƒœã‚¦ãƒ«$i(=1,2)$ãŒé¸ã°ã‚Œã‚‹äº‹è±¡ã‚’$H_i$ã¨ã—ã€ã€Œãƒ—ãƒ¬ãƒ¼ãƒ³ã‚¯ãƒƒã‚­ãƒ¼ãŒå‡ºãŸã€ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚’$D$ã¨ã™ã‚‹ã€‚ç›®çš„ã¯$D$ã‚’å¾—ãŸçŠ¶æ³ä¸‹ã§ã®ãƒœã‚¦ãƒ«ï¼‘ãŒé¸ã°ã‚ŒãŸæ¡ä»¶ä»˜ãç¢ºç‡$\Pr (H_1 \mid D)$ã‚’è¨ˆç®—ã—ã¦ã€ãã‚ŒãŒ50\%ã‚ˆã‚Šå¤§ãã„ã®ã‹å°ã•ã„ã®ã‹ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ã¾ãšãƒœã‚¦ãƒ«ã‚’é¸ã¶ç¢ºç‡ã¯ã©ã¡ã‚‰ã‚‚$\Pr (H_1)=\Pr(H_2)=50\%.~$ãƒœã‚¦ãƒ«ï¼‘ã§ã®$D$ã®ç¢ºç‡ã¯$\Pr(D\mid H_1)=30/40=75\%,~$ãƒœã‚¦ãƒ«ï¼’ã§ã®ç¢ºç‡ã¯$\Pr(D \mid H_2)=20/40=50\%.~$ã“ã‚Œã§è¨ˆç®—ã™ã‚‹æº–å‚™ã¯æ•´ã£ãŸã€‚ãƒ™ã‚¤ã‚ºã®å®šç†ã‹ã‚‰
\begin{eqnarray*}
\Pr (H_1 \mid D) &=& \frac{\Pr(H_1)\Pr(D\mid H_1)}{\Pr (D)}=\frac{\Pr(H_1)\Pr(D\mid H_1)}{\Pr(H_1)\Pr(D\mid H_1)+\Pr(H_2)\Pr(D\mid H_2)} \\
&=& \frac{50\% \times 75\%}{50\% \times 75\% + 50\% \times 50\%}=60\%.
\end{eqnarray*}
ã—ãŸãŒã£ã¦åˆã‚ãƒœã‚¦ãƒ«ï¼‘ãŒé¸ã°ã‚Œã‚‹ç¢ºç‡ã¯50\%ã¨æƒ³å®šã—ã¦ã„ãŸã‚‚ã®ãŒã€ãƒ‡ãƒ¼ã‚¿$D$ã‚’å¾—ãŸã“ã¨ã«ã‚ˆã‚Š60\%ã«ä¿®æ­£ã•ã‚ŒãŸã€‚\\

æµ·å›³ãŒ$10\times 10$ã«åŒºåˆ‡ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ç¯„å›²ã§ã‚ã‚‹æ½œæ°´è‰¦ãŒå¤±è¸ªã—ãŸã€‚ãƒ™ã‚¤ã‚ºæ¨å®šã‚’ç”¨ã„ã¦ä½ç½®ã‚’ç‰¹å®šã—ã€æœç´¢ã—ãŸã„ã€‚å™‚ã«ã‚ˆã‚‹ã¨ã€$(5,6)$ã®å ´æ‰€ã§ã¯

\end{comment}

\newpage
\begin{thebibliography}{9}
  \bibitem{1} ä¸­è°·ç§€æ´‹. ã€Œç¬¬12å›ã€€ãƒ™ã‚¤ã‚ºç·šå½¢å›å¸°ï¼»å‰ç·¨ï¼½ã€. gihyo.jp. \url{https://gihyo.jp/dev/serial/01/machine-learning/0012}ï¼æœ€çµ‚é–²è¦§\today.
  \bibitem{2} å®‰é“çŸ¥å¯›ï¼Œã€Œãƒ™ã‚¤ã‚ºçµ±è¨ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ï¼Œæ ªå¼ä¼šç¤¾æœå€‰æ›¸åº—ï¼Œ2010å¹´ï¼pp.  28--41.
 \end{thebibliography}
\end{document}